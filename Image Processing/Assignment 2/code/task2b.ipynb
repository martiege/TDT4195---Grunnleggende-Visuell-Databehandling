{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import utils\n",
        "import dataloaders\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import os\n",
        "from trainer import Trainer\n",
        "torch.random.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cuda.deterministic = True"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ### START YOUR CODE HERE ### (You can change anything inside this block)\n",
        "        num_input_nodes = 32*32\n",
        "        num_hidden_nodes = 64\n",
        "        num_classes = 10\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_input_nodes, num_hidden_nodes),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(num_hidden_nodes, num_classes)\n",
        "        )\n",
        "        ### END YOUR CODE HERE ### \n",
        "\n",
        "    def forward(self, x):\n",
        "        ### START YOUR CODE HERE ### (You can change anything inside this block) \n",
        "        x = x.view(-1, 32*32) \n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "        ### END YOUR CODE HERE ### \n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameters & Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.0192\n",
        "num_epochs = 4\n",
        "\n",
        "\n",
        "# Use CrossEntropyLoss for multi-class classification\n",
        "loss_function = torch.nn.CrossEntropyLoss()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "image_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32, 32)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.5], [0.25])\n",
        "])\n",
        "dataloader_train, dataloader_val = dataloaders.load_dataset(batch_size, image_transform)\n",
        "\n",
        "# Model definition\n",
        "model = LeNet()\n",
        "# Transfer model to GPU memory (if possible)\n",
        "model = utils.to_cuda(model)\n",
        "\n",
        "# Define optimizer (Stochastic Gradient Descent)\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr=learning_rate)\n",
        "trainer = Trainer(\n",
        "  model=model,\n",
        "  dataloader_train=dataloader_train,\n",
        "  dataloader_val=dataloader_val,\n",
        "  batch_size=batch_size,\n",
        "  loss_function=loss_function,\n",
        "  optimizer=optimizer\n",
        ")\n",
        "train_loss_dict, val_loss_dict = trainer.train(num_epochs)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "utils.plot_loss(train_loss_dict, label=\"Train Loss\")\n",
        "utils.plot_loss(val_loss_dict, label=\"Test Loss\")\n",
        "# Limit the y-axis of the plot (The range should not be increased!)\n",
        "plt.ylim([0, .4])\n",
        "plt.legend()\n",
        "plt.xlabel(\"Global Training Step\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "os.makedirs(\"image_processed\", exist_ok=True)\n",
        "plt.savefig(os.path.join(\"image_processed\", \"task2.png\"))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "torch.save(model.state_dict(), \"saved_model.torch\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# %%\n",
        "final_loss, final_acc = utils.compute_loss_and_accuracy(\n",
        "    dataloader_val, model, loss_function)\n",
        "print(f\"Final Validation loss: {final_loss}. Final Validation accuracy: {final_acc}\")\n",
        "\n",
        "# %%"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}