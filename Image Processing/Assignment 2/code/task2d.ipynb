{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualizing filters in Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = Image.open(\"images/zebra.jpg\")\n",
        "plt.imshow(image)\n",
        "print(\"Image shape:\", image.size)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model definition\n",
        "In this example we will use a pre-trained ResNet50 network. ResNet-50 is a fully-convolutional neural network that excels at image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First convolution layer\n",
        "In this task we are interested in visualizing the first convolutional layer. This can be retrieved by the following code block:\n",
        "\n",
        "We can see that it has 64 filters/kernels in the layer. Each kernel is a $7 \\times 7$ filter, that takes an RGB image as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "first_conv_layer = model.conv1\n",
        "print(\"First conv layer weight shape:\", first_conv_layer.weight.shape)\n",
        "print(\"First conv layer:\", first_conv_layer)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activation from first layer\n",
        "We can retrieve the activation from the first layer by doing a forward pass throught this conv layer.\n",
        "\n",
        "However, first we need to resize, and normalize the image with the mean and standard deviation that they used to originally train this network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = image_transform(image)[None]\n",
        "print(\"Image shape:\", image.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "activation = first_conv_layer(image)\n",
        "print(\"Activation shape:\", activation.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize filters & Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# tip\n",
        "# To transform a weight to a numpy array, you can use to function\n",
        "def torch_image_to_numpy(image: torch.Tensor):\n",
        "    # Normalize to [0 - 1.0]\n",
        "    image = image.detach().cpu() # Transform image to CPU memory (if on GPU VRAM)\n",
        "    image = image - image.min()\n",
        "    image = image / image.max()\n",
        "    image = image.numpy()\n",
        "    if len(image.shape) == 2: # Grayscale image, can just return\n",
        "        return image\n",
        "    assert image.shape[0] == 3, \"Expected color channel to be on first axis. Got: {}\".format(image.shape)\n",
        "    image = np.moveaxis(image, 0, 2)\n",
        "    return image\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "### START YOUR CODE HERE ### (You can change anything inside this block)\n",
        "# plt.subplot is a nice function to use for this task!\n",
        "indices = [5, 8, 19, 22, 34]\n",
        "# %%\n",
        "plt.figure(figsize=(20, 4)) \n",
        "### END YOUR CODE HERE ### "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}