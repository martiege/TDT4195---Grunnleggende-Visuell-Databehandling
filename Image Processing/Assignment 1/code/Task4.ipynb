{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import tqdm\n",
    "import dataloaders\n",
    "import torchvision\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "\n",
    "class FullyConnectedModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We are using 28x28 greyscale images.\n",
    "        num_input_nodes = 28*28\n",
    "        # Number of classes in the MNIST dataset\n",
    "        num_classes = 10\n",
    "\n",
    "        # Define our model\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(num_input_nodes, 64), \n",
    "            # torch.nn.ReLU(), \n",
    "            # torch.nn.Linear(64, num_classes),\n",
    "            torch.nn.Linear(num_input_nodes, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Runs a forward pass on the images\n",
    "        x = x.view(-1, 28*28)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "    \n",
    "class FullyConnectedModelWithHiddenLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We are using 28x28 greyscale images.\n",
    "        num_input_nodes = 28*28\n",
    "        # Number of hidden nodes\n",
    "        num_hidden_nodes = 64\n",
    "        # Number of classes in the MNIST dataset\n",
    "        num_classes = 10\n",
    "\n",
    "        # Define our model\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_input_nodes, num_hidden_nodes), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(num_hidden_nodes, num_classes),\n",
    "            # torch.nn.Linear(num_input_nodes, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Runs a forward pass on the images\n",
    "        x = x.view(-1, 28*28)\n",
    "        out = self.classifier(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters & Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate_good = 0.0192\n",
    "learning_rate_bad  = 1.0\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# Use CrossEntropyLoss for multi-class classification\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Model definition\n",
    "original_model = FullyConnectedModel()\n",
    "better_model   = FullyConnectedModelWithHiddenLayer()\n",
    "\n",
    "# Define optimizer (Stochastic Gradient Descent)\n",
    "original_optimizer_good = torch.optim.SGD(original_model.parameters(),\n",
    "                            lr=learning_rate_good)\n",
    "original_optimizer_bad = torch.optim.SGD(original_model.parameters(),\n",
    "                            lr=learning_rate_bad)\n",
    "better_optimizer = torch.optim.SGD(better_model.parameters(),\n",
    "                            lr=learning_rate_good)\n",
    "\n",
    "image_transform_original = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(), \n",
    "  torchvision.transforms.Normalize([0.5], [0.25])\n",
    "])\n",
    "\n",
    "dataloader_train, dataloader_val = dataloaders.load_dataset(batch_size, image_transform=image_transform)\n",
    "dataloader_train_original, dataloader_val_original = dataloaders.load_dataset(batch_size, image_transform=image_transform_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 938/938 [00:09<00:00, 101.28it/s]\n",
      "Training epoch 1: 100%|██████████| 938/938 [00:09<00:00, 101.34it/s]\n",
      "Training epoch 2: 100%|██████████| 938/938 [00:09<00:00, 102.48it/s]\n",
      "Training epoch 3: 100%|██████████| 938/938 [00:05<00:00, 169.22it/s]\n",
      "Training epoch 4: 100%|██████████| 938/938 [00:09<00:00, 102.75it/s]\n",
      "Training epoch 0: 100%|██████████| 938/938 [00:09<00:00, 102.00it/s]\n",
      "Training epoch 1: 100%|██████████| 938/938 [00:09<00:00, 102.22it/s]\n",
      "Training epoch 2: 100%|██████████| 938/938 [00:09<00:00, 100.52it/s]\n",
      "Training epoch 3: 100%|██████████| 938/938 [00:09<00:00, 100.00it/s]\n",
      "Training epoch 4: 100%|██████████| 938/938 [00:09<00:00, 101.94it/s]\n",
      "Training epoch 0: 100%|██████████| 938/938 [00:09<00:00, 98.10it/s]\n",
      "Training epoch 1: 100%|██████████| 938/938 [00:09<00:00, 100.79it/s]\n",
      "Training epoch 2: 100%|██████████| 938/938 [00:09<00:00, 100.11it/s]\n",
      "Training epoch 3: 100%|██████████| 938/938 [00:09<00:00, 98.16it/s]\n",
      "Training epoch 4: 100%|██████████| 938/938 [00:09<00:00, 99.54it/s]\n"
     ]
    }
   ],
   "source": [
    "original_trainer_good = Trainer(\n",
    "  model=original_model,\n",
    "  dataloader_train=dataloader_train_original,\n",
    "  dataloader_val=dataloader_val_original,\n",
    "  batch_size=batch_size,\n",
    "  loss_function=loss_function,\n",
    "  optimizer=original_optimizer_good\n",
    ")\n",
    "original_trainer_good_normalized = Trainer(\n",
    "  model=original_model,\n",
    "  dataloader_train=dataloader_train,\n",
    "  dataloader_val=dataloader_val,\n",
    "  batch_size=batch_size,\n",
    "  loss_function=loss_function,\n",
    "  optimizer=original_optimizer_good\n",
    ")\n",
    "original_trainer_bad = Trainer(\n",
    "  model=original_model,\n",
    "  dataloader_train=dataloader_train,\n",
    "  dataloader_val=dataloader_val,\n",
    "  batch_size=batch_size,\n",
    "  loss_function=loss_function,\n",
    "  optimizer=original_optimizer_bad\n",
    ")\n",
    "better_trainer = Trainer(\n",
    "  model=better_model,\n",
    "  dataloader_train=dataloader_train,\n",
    "  dataloader_val=dataloader_val,\n",
    "  batch_size=batch_size,\n",
    "  loss_function=loss_function,\n",
    "  optimizer=better_optimizer\n",
    ")\n",
    "\n",
    "original_train_loss_dict_good, original_val_loss_dict_good = original_trainer_good.train(num_epochs)\n",
    "original_train_loss_dict_good_normalized, original_val_loss_dict_good_normalized = original_trainer_good_normalized.train(num_epochs)\n",
    "original_train_loss_dict_bad,  original_val_loss_dict_bad  =  original_trainer_bad.train(num_epochs)\n",
    "better_train_loss_dict,        better_val_loss_dict        =        better_trainer.train(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = next(model.classifier.children()).weight.data\n",
    "print(weight.shape)\n",
    "\n",
    "for w in range(weight.shape[0]):\n",
    "    im = np.zeros((28, 28))\n",
    "    \n",
    "    minimum = weight[w, :].min()\n",
    "    maximum = weight[w, :].max()\n",
    "    \n",
    "    for y in range(28):\n",
    "        for x in range(28):\n",
    "            im[y, x] = float((weight[w, y * 28 + x] - minimum) / (maximum - minimum))\n",
    "    \n",
    "    # plt.imsave(\"weights/hidden_class_\" + str(w) + \"_weight_image.jpg\", im, cmap=\"gray\")\n",
    "    print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original result\n",
    "utils.plot_loss(original_train_loss_dict_good, label=\"Train Loss\")\n",
    "utils.plot_loss(original_val_loss_dict_good, label=\"Test Loss\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Images Seen\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.savefig(\"original_training_loss.png\")\n",
    "\n",
    "plt.show()\n",
    "torch.save(original_model.state_dict(), \"original_saved_model.torch\")\n",
    "final_loss, final_acc = utils.compute_loss_and_accuracy(\n",
    "    dataloader_val_original, original_model, loss_function)\n",
    "print(f\"Final Test Cross Entropy Loss: {final_loss}. Final Test accuracy: {final_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original vs normalized results\n",
    "utils.plot_loss(original_train_loss_dict_good, label=\"Train Loss\")\n",
    "utils.plot_loss(original_val_loss_dict_good, label=\"Test Loss\")\n",
    "utils.plot_loss(original_train_loss_dict_good_normalized, label=\"Train Loss, Normalized\")\n",
    "utils.plot_loss(original_val_loss_dict_good_normalized, label=\"Test Loss, Normalized\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Images Seen\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.savefig(\"original_vs_normalized_training_loss.png\")\n",
    "\n",
    "plt.show()\n",
    "torch.save(original_model.state_dict(), \"original_saved_model.torch\")\n",
    "final_loss, final_acc = utils.compute_loss_and_accuracy(\n",
    "    dataloader_val, original_model, loss_function)\n",
    "print(f\"Normalized Final Test Cross Entropy Loss: {final_loss}. Final Test accuracy: {final_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bad learning rate\n",
    "utils.plot_loss(original_train_loss_dict_bad, label=\"Train Loss\")\n",
    "utils.plot_loss(original_val_loss_dict_bad, label=\"Test Loss\")\n",
    "plt.ylim([0, 100])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Images Seen\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.savefig(\"bad_learning_rate_training_loss.png\")\n",
    "\n",
    "plt.show()\n",
    "torch.save(original_model.state_dict(), \"original_saved_model.torch\")\n",
    "final_loss, final_acc = utils.compute_loss_and_accuracy(\n",
    "    dataloader_val, original_model, loss_function)\n",
    "print(f\"Normalized Final Test Cross Entropy Loss: {final_loss}. Final Test accuracy: {final_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized vs hidden layer model results\n",
    "utils.plot_loss(original_train_loss_dict_good_normalized, label=\"Train Loss\")\n",
    "utils.plot_loss(original_val_loss_dict_good_normalized, label=\"Test Loss\")\n",
    "utils.plot_loss(better_train_loss_dict, label=\"Train Loss, Hidden Layer\")\n",
    "utils.plot_loss(better_val_loss_dict, label=\"Test Loss, Hidden Layer\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Images Seen\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.savefig(\"normalized_vs_hidden_layer_training_loss.png\")\n",
    "\n",
    "plt.show()\n",
    "torch.save(better_model.state_dict(), \"better_saved_model.torch\")\n",
    "final_loss, final_acc = utils.compute_loss_and_accuracy(\n",
    "    dataloader_val, better_model, loss_function)\n",
    "print(f\"Normalized Final Test Cross Entropy Loss: {final_loss}. Final Test accuracy: {final_acc}\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "visdat",
   "language": "python",
   "name": "visdat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
